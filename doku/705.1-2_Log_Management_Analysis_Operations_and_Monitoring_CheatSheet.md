# Cheat-Sheet – 705.1 IT Operations and Monitoring

| Begriff / Tool           | Beschreibung | Typischer Einsatzzweck |
|--------------------------|--------------|------------------------|
| **Prometheus**           | Zeitreihendatenbank, Pull-basiert, sammelt Metriken über HTTP | Infrastruktur- und Applikationsmonitoring |
| **Node Exporter**        | Exporter für Host-Metriken (CPU, RAM, Disk, Netzwerk) | Systemmetriken für Prometheus |
| **Pushgateway**          | Zwischenspeicher für kurzlebige Jobs (Push → Pull) | Metriken von Batchjobs, die beim nächsten Prometheus-Pull abgeholt werden |
| **Alertmanager**         | Alert-Verwaltung (Deduplizierung, Routing) | Alarmierung per E-Mail, Slack, Webhook |
| **Grafana**              | Visualisierung von Zeitreihen- und Logdaten | Dashboards für Prometheus, Loki, Elasticsearch |
| **Loki**                 | Logaggregation in Kombination mit Grafana | Zentralisierte Loganalyse |
| **Fluentd / Logstash**   | Log-Sammlung und -Weiterleitung | Teil der ELK-/EFK-Stacks |
| **SLI**                  | Messgröße (z. B. Latenz, Fehlerquote) | Grundlage für SLO |
| **SLO**                  | Zielwert für eine SLI (z. B. „99,9 % Verfügbarkeit“) | Internes Qualitätsziel |
| **SLA**                  | Vertragliche Vereinbarung mit Kunden, inkl. Konsequenzen bei Nichterfüllung | Externe Serviceverpflichtung |

## Monitoring-Modelle
- **Pull-basiert**: Monitoring-System fragt aktiv beim Ziel ab (Prometheus, Nagios NRPE)  
- **Push-basiert**: Zielsystem sendet Daten aktiv (SNMP-Traps, Pushgateway)  

## Best Practices
- Kombination von *Monitoring* (Metriken) + *Logging* (Logs) + *Tracing* (Verfolgung von Requests) → vollständige Observability  
- Alerts priorisieren und nur relevante Events senden (Vermeidung von Alarmmüdigkeit)  
- Historische Daten zur Trendanalyse nutzen  

# Cheat-Sheet – 705.2 Log Management and Analysis

| Begriff / Tool        | Beschreibung | Typischer Einsatzzweck |
|-----------------------|--------------|------------------------|
| **systemd-journald**  | Binäres, strukturiertes Logging-System, integriert in systemd | Zentraler Logdienst für Linux-Systeme |
| **journalctl**        | CLI-Tool zum Abfragen und Filtern des systemd-Journals | Analyse von Logs nach Zeit, Priorität, Unit |
| **rsyslog**           | Syslog-Implementierung mit Netzwerkweiterleitung, Filterregeln | Zentrales Logging, Weiterleitung an Server |
| **Fluentd**           | Log-Collector, unterstützt viele Input-/Output-Plugins | Sammeln und Weiterleiten von Logs |
| **Logstash**          | Teil des ELK-Stacks, Logverarbeitung und Parsing | Aufbereitung vor Speicherung in Elasticsearch |
| **Loki**              | Logaggregation optimiert für Integration in Grafana | Zeitbasierte Analyse von Logs |
| **Elasticsearch**     | Such- und Analyse-Engine | Speicherung und schnelle Suche von Logdaten |
| **Kibana**            | Visualisierungstool für Elasticsearch-Daten | Dashboards und Analysen für Logs |
| **Logformate**        | JSON, Plaintext, Binär (systemd), teilweise XML | Speicherung und Austausch von Logs |
| **Zentrales Logging** | Sammlung aller Logs an einem Ort | Ereigniskorrelation, Compliance, Sicherheit |

## Wichtige `journalctl`-Parameter
- `-u <unit>` → Logs einer bestimmten Unit  
- `-p <prio>.. <prio>` → Prioritätsfilter (z. B. `crit..emerg`)  
- `-n <Zahl>` → letzte X Einträge  
- `--since` / `--until` → Zeitfilter  

## Best Practices
- Strukturierte Logs (JSON) bevorzugen → leichtere Analyse  
- Zentrales Logging zur Compliance und forensischen Analyse  
- Zugriffsrechte auf Logs restriktiv setzen (oft sensible Daten)  
- Rotations- und Aufbewahrungsrichtlinien beachten  
